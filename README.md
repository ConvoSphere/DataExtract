# Universal File Extractor API

Eine einheitliche API fÃ¼r die Extraktion von Inhalten aus verschiedenen Dateiformaten, entwickelt mit FastAPI, **docling** fÃ¼r erweiterte Datenextraktion, **UV** als Package Manager und **Ruff** fÃ¼r Code-QualitÃ¤t.

## ğŸš€ Features

### UnterstÃ¼tzte Dateiformate

- **Dokumente**: PDF, DOCX, DOC, RTF, ODT, TXT
- **Tabellen**: XLSX, XLS, ODS, CSV
- **PrÃ¤sentationen**: PPTX, PPT, ODP
- **Datenformate**: JSON, XML, HTML, YAML
- **Bilder**: JPG, PNG, GIF, BMP, TIFF, WebP, SVG
- **Medien**: MP4, AVI, MOV, MP3, WAV, FLAC
- **Archive**: ZIP, RAR, 7Z, TAR, GZ

### Kernfunktionen

- **Einheitliche API**: Einheitliche Schnittstelle fÃ¼r alle Dateiformate
- **Docling Integration**: Erweiterte Datenextraktion mit docling
- **Asynchrone Verarbeitung**: Parallele Verarbeitung groÃŸer Dateien
- **OCR-UnterstÃ¼tzung**: Texterkennung in Bildern und PDFs
- **Medien-Extraktion**: Audio/Video-Transkription
- **Strukturierte Daten**: Tabellen, Listen, Ãœberschriften
- **Metadaten**: Umfassende Datei-Informationen
- **Skalierbar**: Cloud-ready mit Docker und Kubernetes

### Technische Highlights

- **150MB DateigrÃ¶ÃŸe**: UnterstÃ¼tzung fÃ¼r groÃŸe Dateien
- **Parallelisierung**: Bis zu 10 gleichzeitige Extraktionen
- **Verarbeitungspipeline**: Asynchrone Job-Queue mit Redis/Celery
- **Monitoring**: Prometheus/Grafana Integration
- **Container-basiert**: Einfaches Cloud-Deployment
- **UV Package Manager**: Schnelle Dependency-Verwaltung
- **Ruff Linting**: Moderne Code-QualitÃ¤t

## ğŸ› ï¸ Schnellstart

### Voraussetzungen

- Python 3.8+
- UV (Package Manager)
- Docker (optional)

### Installation

```bash
# UV installieren (falls nicht vorhanden)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Repository klonen
git clone https://github.com/yourusername/universal-file-extractor-api
cd universal-file-extractor-api

# Mit UV installieren
uv sync

# Pre-commit Hooks installieren
uv pip install pre-commit
pre-commit install

# Mit Docker (empfohlen)
docker-compose up -d

# Oder lokal
uv run uvicorn app.main:app --reload
```

### Erste Schritte

```python
import requests

# Datei hochladen und extrahieren
with open('document.pdf', 'rb') as f:
    files = {'file': f}
    response = requests.post('http://localhost:8000/api/v1/extract', files=files)
    
result = response.json()
print(f"Extrahierter Text: {result['extracted_text']['content'][:200]}...")
```

### Asynchrone Verarbeitung

```python
# Asynchrone Extraktion fÃ¼r groÃŸe Dateien
response = requests.post(
    'http://localhost:8000/api/v1/extract/async',
    files={'file': open('large_document.pdf', 'rb')},
    data={'priority': 'high'}
)

job_id = response.json()['job_id']

# Status abfragen
status = requests.get(f'http://localhost:8000/api/v1/jobs/{job_id}').json()
print(f"Status: {status['status']}, Fortschritt: {status['progress']}%")
```

## ğŸ“Š API-Ãœbersicht

### Haupt-Endpoints

| Endpoint | Methode | Beschreibung |
|----------|---------|--------------|
| `/api/v1/extract` | POST | Synchrone Datei-Extraktion |
| `/api/v1/extract/async` | POST | Asynchrone Datei-Extraktion |
| `/api/v1/jobs/{job_id}` | GET | Job-Status abfragen |
| `/api/v1/formats` | GET | UnterstÃ¼tzte Formate |
| `/api/v1/health` | GET | API-Status |

### Response-Format

```json
{
  "success": true,
  "file_metadata": {
    "filename": "document.pdf",
    "file_size": 1024000,
    "file_type": "application/pdf",
    "page_count": 5
  },
  "extracted_text": {
    "content": "Extrahierter Text...",
    "word_count": 1500,
    "character_count": 8500,
    "language": "de",
    "ocr_used": false
  },
  "structured_data": {
    "tables": [...],
    "headings": [...],
    "images": [...],
    "entities": {...},
    "sentiment": {...}
  },
  "extraction_time": 2.5
}
```

## ğŸ—ï¸ Architektur

### Komponenten

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI App   â”‚    â”‚  Celery Worker  â”‚    â”‚   Redis Queue   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ HTTP Server   â”‚â—„â”€â”€â–ºâ”‚ â€¢ File Processingâ”‚â—„â”€â”€â–ºâ”‚ â€¢ Job Queue     â”‚
â”‚ â€¢ API Routes    â”‚    â”‚ â€¢ OCR/Media     â”‚    â”‚ â€¢ Results Cache â”‚
â”‚ â€¢ Validation    â”‚    â”‚ â€¢ Parallel Exec â”‚    â”‚ â€¢ State Mgmt    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  File Extractorsâ”‚    â”‚  Monitoring     â”‚    â”‚  Storage        â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Docling       â”‚    â”‚ â€¢ Prometheus    â”‚    â”‚ â€¢ Temp Files    â”‚
â”‚ â€¢ PDF Extractor â”‚    â”‚ â€¢ Grafana       â”‚    â”‚ â€¢ Results       â”‚
â”‚ â€¢ Image Extractorâ”‚   â”‚ â€¢ Health Checks â”‚    â”‚ â€¢ Logs          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Docling Integration

Die API nutzt **docling** fÃ¼r erweiterte Datenextraktion:

- **Text-Extraktion**: Intelligente Texterkennung
- **Metadaten**: Umfassende Datei-Informationen
- **Struktur-Analyse**: Tabellen, Ãœberschriften, Listen
- **EntitÃ¤ten-Erkennung**: Personen, Orte, Organisationen
- **Sentiment-Analyse**: Stimmungsanalyse
- **Zusammenfassung**: Automatische Dokumentenzusammenfassung
- **Spracherkennung**: Automatische Spracherkennung

### Deployment-Optionen

- **Docker Compose**: FÃ¼r Entwicklung und kleine Produktionsumgebungen
- **Kubernetes**: FÃ¼r groÃŸe, skalierbare Deployments
- **Cloud Services**: AWS, Azure, Google Cloud
- **Serverless**: AWS Lambda, Google Cloud Functions

## ğŸ“ˆ Performance

### Benchmarks

| Dateityp | GrÃ¶ÃŸe | Verarbeitungszeit | Speicher |
|----------|-------|-------------------|----------|
| PDF (Text) | 1MB | 0.5s | 50MB |
| PDF (OCR) | 1MB | 3.0s | 100MB |
| DOCX | 1MB | 1.0s | 30MB |
| Bild (OCR) | 5MB | 2.5s | 80MB |
| Video (5min) | 50MB | 30.0s | 200MB |

### Skalierung

- **Parallele Jobs**: Bis zu 10 gleichzeitig
- **Worker-Instanzen**: Horizontale Skalierung
- **DateigrÃ¶ÃŸe**: Bis zu 150MB pro Datei
- **Timeout**: 10 Minuten pro Extraktion

## ğŸ”§ Konfiguration

### Umgebungsvariablen

```bash
# API-Konfiguration
DEBUG=false
MAX_FILE_SIZE=157286400  # 150MB
ENABLE_ASYNC_PROCESSING=true

# Redis-Konfiguration
REDIS_URL=redis://localhost:6379

# Worker-Konfiguration
MAX_CONCURRENT_EXTRACTIONS=10
WORKER_PROCESSES=4

# Docling-Konfiguration
ENABLE_DOCLING=true
ENABLE_ADVANCED_ANALYSIS=true
DOCLING_TIMEOUT=300

# OCR-Konfiguration
EXTRACT_IMAGE_TEXT=true
EXTRACT_AUDIO_TRANSCRIPT=false
```

## ğŸ› ï¸ Entwicklung

### UV Package Manager

```bash
# Dependencies installieren
uv sync

# Neue Dependency hinzufÃ¼gen
uv add package-name

# Dev-Dependency hinzufÃ¼gen
uv add --dev package-name

# Dependency entfernen
uv remove package-name

# Dependencies aktualisieren
uv lock --upgrade
```

### Ruff Linting

```bash
# Code formatieren
uv run ruff format app/ tests/

# Linting mit Auto-Fix
uv run ruff check --fix app/ tests/

# Import-Sortierung
uv run ruff check --select I app/ tests/

# VollstÃ¤ndiger Check
uv run ruff check app/ tests/
```

### Makefile-Befehle

```bash
# Entwicklungssetup
make setup-dev

# Code-QualitÃ¤t
make quality

# Tests ausfÃ¼hren
make test

# Dokumentation starten
make docs

# Docker-Deployment
make setup-prod
```

## ğŸ“š Dokumentation

- **[API-Dokumentation](api/overview.md)**: VollstÃ¤ndige API-Referenz
- **[Entwickler-Guide](development/installation.md)**: Installation und Setup
- **[Extraktoren](extractors/overview.md)**: Details zu allen Extraktoren
- **[Docling Integration](extractors/docling.md)**: Docling-spezifische Features
- **[Deployment](deployment/docker.md)**: Cloud-Deployment-Anleitung
- **[Beispiele](examples/quickstart.md)**: Code-Beispiele in verschiedenen Sprachen

## ğŸ¤ Beitragen

Wir freuen uns Ã¼ber BeitrÃ¤ge! Bitte lesen Sie unsere [Contributing Guidelines](CONTRIBUTING.md).

### Entwicklung

```bash
# Entwicklungsumgebung einrichten
make setup-dev

# Code-QualitÃ¤t prÃ¼fen
make quality

# Tests ausfÃ¼hren
make test

# Dokumentation bauen
make docs-build
```

### Pre-commit Hooks

Das Projekt nutzt Pre-commit Hooks fÃ¼r automatische Code-QualitÃ¤t:

- **Ruff**: Linting und Formatierung
- **MyPy**: Type Checking
- **Pre-commit Hooks**: Allgemeine Checks
- **UV Sync**: Dependency-Synchronisation

## ğŸ“„ Lizenz

Dieses Projekt steht unter der MIT-Lizenz. Siehe [LICENSE](LICENSE) fÃ¼r Details.

## ğŸ†˜ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/universal-file-extractor-api/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/universal-file-extractor-api/discussions)
- **Email**: support@yourdomain.com

---

**Entwickelt mit â¤ï¸, FastAPI, docling, UV und Ruff**